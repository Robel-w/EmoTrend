# ğŸ“˜ EmoTrend â€“ Emotional Intensity Prediction Engine

A lightweight NLP + Linear Regression system that quantifies the **strength of human emotions** in text.

---

## ğŸ” Overview

**EmoTrend** predicts the **intensity of emotion** expressed in any sentence.  
Unlike conventional sentiment classifiers that output simple labels (positive/negative), EmoTrend produces a **continuous score** (0â€“1 or 0â€“100) representing emotional strength.  

This project combines **classical ML (Linear Regression)**, **NLP preprocessing**, **feature engineering**, and **evaluation metrics** to emulate how humans perceive emotion intensity in text.

---

## ğŸ¯ Objectives

- Build an ML model using **Linear Regression** to estimate emotional intensity.
- Apply classical **NLP preprocessing techniques**.
- Engineer **linguistic and sentiment-based features**.
- Compare multiple regression models:
  - Linear Regression
  - Ridge Regression
  - Lasso Regression
  - ElasticNet
- Deploy the final model through a **clean prediction pipeline** (CLI or API).

---

## ğŸ§  How It Works

### 1. Preprocessing

- Lowercasing  
- Stopword removal  
- Lemmatization  
- Tokenization  
- TF-IDF vectorization  

### 2. Feature Engineering

In addition to TF-IDF, EmoTrend uses:

- **Sentiment polarity** (VADER or TextBlob)  
- **Punctuation markers** (e.g., number of exclamation marks)  
- **Emotion lexicon counts** (NRC or custom lists)  
- **Sentence length metrics**  

These features capture **emotional nuances** in a simple and explainable way.

---

## ğŸ§© Modeling Approach

Trained & evaluated using **scikit-learn**:

| Model             | Purpose                        |
|------------------|--------------------------------|
| Linear Regression | Baseline model                 |
| Ridge Regression  | Handles multicollinearity       |
| Lasso Regression  | Feature selection              |
| ElasticNet        | Balanced regularization         |

### Evaluation Metrics

- Mean Absolute Error (MAE)  
- Mean Squared Error (MSE)  
- RÂ² Score  

The **best-performing model** is selected for deployment.

---

## ğŸ“Š Dataset

Two options for experimentation:

**Option A:** SemEval 2018 â€“ Emotion Intensity Dataset  
Labels emotions (anger, joy, fear, sadness) from 0â€“1.

**Option B:** Self-built dataset of 200â€“300 manually labeled sentences.  

Data files are stored under:

/data/raw.csv
/data/processed.csv


---

## ğŸ› ï¸ Project Structure

EmoTrend/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw.csv
â”‚ â””â”€â”€ processed.csv
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ best_model.pkl
â”‚ â”œâ”€â”€ vectorizer.pkl
â”‚ â””â”€â”€ scaler.pkl
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_preprocessing.ipynb
â”‚ â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚ â””â”€â”€ 03_model_training.ipynb
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ preprocess.py
â”‚ â”œâ”€â”€ features.py
â”‚ â”œâ”€â”€ model.py
â”‚ â””â”€â”€ predict.py
â”‚
â”œâ”€â”€ api/
â”‚ â”œâ”€â”€ main.py
â”‚ â””â”€â”€ routes.py
â”‚
â”œâ”€â”€ tests/
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt


---

## ğŸš€ Usage

### 1. Install dependencies

```bash
pip install -r requirements.txt

2. Run model training
python src/model.py

3. Predict emotion intensity
python src/predict.py "I am extremely excited today!"


Output:

{
  "emotion_intensity": 0.87
}

ğŸŒ API (Optional Enhancement)

Using FastAPI:

POST /predict

{
  "text": "I am extremely happy!"
}


Response:

{
  "intensity": 0.82
}

ğŸ’¡ Notes & Next Steps

Feature expansion: Use n-grams, word embeddings (Word2Vec, GloVe) for richer features.

Model experimentation: Explore tree-based regressors (RandomForest, XGBoost) for comparison.

Deployment: Containerize via Docker or deploy on Heroku/Streamlit/FastAPI for live prediction.


---

If you want, I can also **add badges and a visually modern GitHub-style header** to make it pop for recruiters when they see your repo. This is often what makes an AI project *look professional at first glance*. Do you want me to do that?
